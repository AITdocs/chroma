# 单节点 Chroma：性能与限制

Chroma 的单节点版本设计为易于部署和维护，同时仍提供满足广泛生产应用场景的稳健性能。

为了帮助您判断单节点 Chroma 是否适用于您的用例，我们进行了一系列压力测试和性能实验，以探测系统的性能边界、限制和边缘情况。我们在多种硬件配置下分析了这些边界，以确定针对不同工作负载的适当部署方式。

本文档描述了这些发现，以及一些通用原则，帮助您最大限度地发挥 Chroma 部署的性能。

## 结果概览

大致而言，以下是使用典型工作负载时，在不同 EC2 实例类型上 Chroma 的预期性能：

- 嵌入维度：1024
- 小型文档（100-200 字）
- 每条记录包含三个元数据字段

| 实例类型        | 系统内存 (GB) | 近似最大集合大小 | 平均延迟（查询） | 99.9% 延迟（查询） | 平均延迟（插入，批次大小=32） | 99.9% 延迟（插入，批次大小=32） | 月费用     |
|-----------------|---------------|------------------|------------------|--------------------|-------------------------------|----------------------------------|------------|
| **r7i.2xlarge** | 64            | 15,000,000       | 5ms             | 7ms               | 112ms                          | 405ms                             | $386.944   |
| **t3.2xlarge**  | 32            | 7,500,000        | 5ms             | 33ms              | 149ms                          | 520ms                             | $242.976   |
| **t3.xlarge**   | 16            | 3,600,000        | 4ms             | 7ms               | 159ms                          | 530ms                             | $121.888   |
| **t3.large**    | 8             | 1,700,000        | 4ms             | 10ms              | 199ms                          | 633ms                             | $61.344    |
| **t3.medium**   | 4             | 700,000          | 5ms             | 18ms              | 191ms                          | 722ms                             | $31.072    |
| **t3.small**    | 2             | 250,000          | 8ms             | 29ms              | 231ms                          | 1280ms                            | $15.936    |

{% br %}{% /br %}

**不推荐**在小于 2GB 内存的系统上部署 Chroma。

注意：表中的延迟数据是针对小集合的。随着集合增大，延迟也会增加：有关完整分析，请参见下方 [延迟与集合大小](./performance#latency-and-collection-size)。

## 内存与集合大小

Chroma 使用 [`hnswlib`](https://github.com/nmslib/hnswlib) 的一个分支来高效地对嵌入向量进行索引和搜索。HNSW 算法要求在系统 RAM 中驻留嵌入索引以进行查询或更新。

因此，可用系统内存决定了 Chroma 集合（或多个同时使用的集合）的最大大小。如果集合超过可用内存，操作系统开始将内存交换到磁盘时，插入和查询的延迟将迅速上升。索引的内存布局不利于交换，系统很快变得不可用。

因此，用户应始终规划足够的内存来容纳预期的嵌入总数。

为了分析所需内存，我们在不同大小的 EC2 实例上启动了 Chroma 实例，然后插入嵌入直到系统无响应。正如预期，该故障点与内存和嵌入数量呈线性关系。

对于 1024 维嵌入，每个嵌入包含三个元数据记录和一个小型文档的情况，其关系为 `N = R * 0.245`，其中 `N` 是最大集合大小（百万单位），`R` 是所需系统内存（GB 单位）。请注意，您还需要预留至少 1GB 内存用于系统其他需求以及 Chroma 所需的内存。

该模式在测试到约 700 万个嵌入时仍然成立。此时 Chroma 仍保持快速和稳定，我们未发现 Chroma 数据库大小的严格上限。

## 磁盘空间与集合大小

Chroma 会将每个集合持久化到磁盘。所需空间由 HNSW 嵌入索引的存储空间以及用于存储文档和嵌入元数据的 SQLite 数据库所需空间组成。

HNSW 索引的持久化计算方式与计算内存大小类似。经验法则是：确保系统的存储空间至少与内存一样大，并额外预留几个 GB 以应对操作系统和其他应用程序的开销。

SQLite 数据库所需的存储空间高度可变，完全取决于是否在 Chroma 中保存文档和元数据，以及它们的大小。例如，一个包含约 4 万个、每篇约 1000 字的文档和约 60 万个元数据条目的集合，其 SQLite 数据库大小约为 1.7GB。

SQLite 数据库本身没有严格的大小上限：SQLite 支持达到 TB 级别的数据库，并且可以有效地进行磁盘分页。

在大多数实际用例中，HNSW 索引在内存中的大小和性能很可能是限制 Chroma 集合大小的首要因素，远早于元数据数据库的限制。

## 延迟与集合大小

随着集合的增大和索引规模的增长，插入和查询所需的时间都会变长。增长速率起初较为平缓，然后大致呈线性增长，拐点和斜率取决于可用 CPU 的数量和速度。某些实例（例如 `t3.2xlarge`）在图表末尾出现极端峰值，是因为实例达到了内存限制。

### 查询延迟

{% MarkdocImage lightSrc="/query_latency_1_0_10_light.png" darkSrc="/query_latency_1_0_10.png" alt="查询延迟性能" %}
{% /MarkdocImage %}

### 插入延迟

{% MarkdocImage lightSrc="/insert_latency_1_0_10_light.png" darkSrc="/insert_latency_1_0_10.png" alt="插入延迟性能" %}
{% /MarkdocImage %}

{% note type="tip" title="" %}
如果您使用多个集合，其性能与所有集合中嵌入向量总数有关，看起来非常相似。将集合拆分成多个较小的集合不会带来好处，但也不会造成损害，只要它们能同时容纳在内存中即可。
{% /note %}

## 并发性

系统可以并行处理并发操作。对于插入操作，由于写入会被写入日志，并且每 N 次操作刷新一次，因此平均延迟不会随着写入者数量的增加而波动，但会随着批次大小的增加而增加，因为较大的批次更可能达到刷新阈值。查询操作可以并行化到实例中可用 vCPU 数量的程度，之后将开始排队，从而导致延迟呈线性增加。

{% MarkdocImage lightSrc="/concurrent_writes_1_0_10_light.png" darkSrc="/concurrent_writes_1_0_10.png" alt="并发写入" %}
{% /MarkdocImage %}

{% MarkdocImage lightSrc="/concurrent_queries_1_0_10_light.png" darkSrc="/concurrent_queries_1_0_10.png" alt="并发查询" %}
{% /MarkdocImage %}

关于在您可以控制并发性的场景下（例如插入批量数据时）如何优化用户数量以实现最大吞吐量的讨论，请参见下面的 [插入吞吐量](./performance#insert-throughput) 部分。

# CPU 速度、核心数量与类型

{% MarkdocImage lightSrc="/cpu_mean_query_latency_1_0_10_light.png" darkSrc="/cpu_mean_query_latency_1_0_10.png" alt="CPU 平均查询延迟" %}
{% /MarkdocImage %}

# 插入吞吐量

一个经常相关的问题是：给定需要插入的批量数据，最快能有多快完成，以及快速插入大量数据的最佳方式是什么？

第一个需要考虑的重要因素是并发插入请求的数量。

如上文 [并发性](./performance#concurrency) 部分所述，插入吞吐量确实受益于增加的并发性。第二个需要考虑的因素是每个请求的批次大小。由于较小批次的开销较高，性能会随着批次大小的增加而提升，直到达到 CPU 饱和点。在达到 CPU 饱和点后，当批次大小约为 150 时，吞吐量趋于稳定。

实验结果证实了这一点：在批次大小为 100-500 之间时，整体吞吐量（跨批次大小和请求数量的插入嵌入总数）保持相对平稳：

{% MarkdocImage lightSrc="/concurrent_inserts_1_0_10_light.png" darkSrc="/concurrent_inserts_1_0_10.png" alt="并发插入" %}
{% /MarkdocImage %}

鉴于较小的批次具有较低且更一致的延迟，并且不太可能导致超时错误，我们建议采用这个曲线范围内较小的批次：50 到 250 之间的任何值都是合理的选择。

## 结论

当部署在合适的硬件上时，用户可以放心地将 Chroma 用于接近千万级嵌入向量的用例。它的平均和上限延迟对于读写操作都表现良好，使其成为除最大规模 AI 应用之外的优秀平台，能够支持潜在的数千名同时在线的人类用户（具体取决于您的应用程序后端访问模式）。

然而，作为一个单节点解决方案，它无法无限扩展。如果您发现您的需求超出了本分析中列出的参数范围，我们非常有兴趣听取您的意见。请填写 [此表单](https://airtable.com/appqd02UuQXCK5AuY/pagr1D0NFQoNpUpNZ/form)，我们将邀请您加入一个专用的 Slack 工作区，用于支持生产环境用户。我们很乐意帮助您思考系统设计，无论是 Chroma 是否适合您的项目，还是您是否适合加入我们即将推出的分布式云服务。